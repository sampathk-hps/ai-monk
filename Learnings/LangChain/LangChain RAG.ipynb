{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMJ1VoJ7VokP/qbjeMb+CWB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Section 1"],"metadata":{"id":"ZJRDNwHI2rnf"}},{"cell_type":"markdown","source":["## Contents\n","\n","* LLM Creation"],"metadata":{"id":"AZAXePnw2uok"}},{"cell_type":"markdown","source":["## LLM"],"metadata":{"id":"yDEgLyH72crR"}},{"cell_type":"code","source":["%pip install --upgrade --quiet langchain-nvidia-ai-endpoints"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vr5q9llg2_cf","executionInfo":{"status":"ok","timestamp":1765121770284,"user_tz":-330,"elapsed":7905,"user":{"displayName":"Sam K","userId":"13411932392943204951"}},"outputId":"c10c6944-f551-43a9-9529-555d138a696e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/46.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","metadata":{"id":"06153cc0","executionInfo":{"status":"ok","timestamp":1765121789454,"user_tz":-330,"elapsed":18711,"user":{"displayName":"Sam K","userId":"13411932392943204951"}}},"source":["import os\n","from google.colab import userdata\n","from langchain_nvidia_ai_endpoints import ChatNVIDIA\n","\n","llm_key: str = userdata.get('NVIDIA_API_KEY')\n","os.environ[\"NVIDIA_API_KEY\"] = llm_key\n","\n","llm = ChatNVIDIA(model=userdata.get('NVIDIA_MODEL'))"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# Section 2 - Loaders"],"metadata":{"id":"PdULRnI7_sxN"}},{"cell_type":"markdown","source":["Loaders are a core part of the LangChain framework, designed to ingest data from various sources—text, PDFs, web pages, databases, emails, and more—so you can process, chunk, embed, or use it in RAG or LLM pipelines."],"metadata":{"id":"B6idAWafAHwr"}},{"cell_type":"markdown","source":["## Contents\n","\n","* TextLoader\n","* DirectoryLoader\n","* PyPDFLoader\n","* CSVLoader\n","* WebBaseLoader\n","* SQLDatabaseLoader"],"metadata":{"id":"eo4MhQbl_uR8"}},{"cell_type":"code","source":["!pip install -qU langchain-community"],"metadata":{"id":"CAhwQE76A3Gi","executionInfo":{"status":"ok","timestamp":1765121827910,"user_tz":-330,"elapsed":10318,"user":{"displayName":"Sam K","userId":"13411932392943204951"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## TextLoader\n","\n","`TextLoader` is a simple document loader that reads plain text files and converts them into LangChain Document objects.\n","\n","`TextLoader` creates ONE Document object per file."],"metadata":{"id":"0F4C-g8rAdS6"}},{"cell_type":"code","source":["from langchain_community.document_loaders import TextLoader\n","from pathlib import Path\n","\n","# Load a text file\n","\n","# More robust path handling in production\n","# file_path = Path(__file__).parent / \"data\" / \"ai_data.txt\"\n","\n","file_path = \"./data/ai_data.txt\"\n","\n","try:\n","    loader = TextLoader(file_path)\n","    documents = loader.load()\n","except FileNotFoundError:\n","    print(\"File not found\")\n","except UnicodeDecodeError:\n","    print(\"File encoding issue - may not be UTF-8\")\n","\n","print(type(documents[0]))\n","print('------')\n","\n","# Documents is a list with one Document object\n","print(documents[0].page_content)  # The text content\n","print('------')\n","print(documents[0].metadata)      # Metadata like file path"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cb0Xp4CwAty9","executionInfo":{"status":"ok","timestamp":1765031492772,"user_tz":-330,"elapsed":34,"user":{"displayName":"Sam K","userId":"13411932392943204951"}},"outputId":"917c2c9e-9e54-49d5-983f-03bf7ad13066"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'langchain_core.documents.base.Document'>\n","------\n","\n","Page 1: Introduction to Artificial Intelligence\n","Artificial Intelligence (AI) is the field of computer science focused on creating machines that can perform tasks that normally require human intelligence. \n","These tasks include understanding language, recognizing images, making decisions, and solving complex problems. \n","AI has grown rapidly due to the explosion of data, better algorithms, and powerful computing hardware. \n","Today, AI is used in voice assistants, search engines, navigation apps, fraud detection systems, and medical diagnosis tools. \n","The main goal of AI is to build systems that can adapt, learn, and improve without being explicitly programmed for every scenario.\n","\n","Page 2: How AI Learns and Makes Decisions\n","AI systems learn through data. Machine Learning, a branch of AI, allows computers to find patterns inside large datasets. \n","For example, an AI that identifies cats in photos is trained using thousands of labeled images. Over time, it understands the patterns—shapes, colors, textures—that define a cat. \n","Deep Learning, an advanced type of machine learning, uses neural networks inspired by the human brain. These networks can analyze huge amounts of information, detect subtle patterns, and make predictions with high accuracy. \n","AI models improve as they receive more diverse and high‑quality data. However, they are only as good as the data they learn from. Poor data leads to poor decisions.\n","\n","Page 3: The Future of AI and Its Impact\n","AI will influence every industry—healthcare, finance, transportation, retail, entertainment, and education. \n","Self-driving cars will reduce traffic accidents. AI doctors will assist human doctors in diagnosing illnesses earlier. \n","Businesses will use AI to automate routine tasks, allowing employees to focus on creative and strategic work. \n","At the same time, AI raises concerns about privacy, job displacement, and ethical decision‑making. \n","The future of AI depends on responsible development, transparent systems, and laws that protect people while encouraging innovation. \n","If used wisely, AI can boost global productivity, improve quality of life, and unlock ideas that were once impossible.\n","\n","------\n","{'source': './data/ai_data.txt'}\n"]}]},{"cell_type":"markdown","source":["## DirectoryLoader\n","\n","If you have multiple files to load, use `DirectoryLoader` to load all of them at once."],"metadata":{"id":"9vpxjO_PCbEp"}},{"cell_type":"code","source":["from langchain_community.document_loaders import DirectoryLoader\n","\n","# Load all .txt files from a directory\n","loader = DirectoryLoader(\n","    path=\"./data\",\n","    glob=\"**/*.txt\",  # Recursively find all .txt files\n","    loader_cls=TextLoader\n",")\n","documents = loader.load()\n","\n","print(f\"Loaded {len(documents)} documents\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IrX26ZKRClrd","executionInfo":{"status":"ok","timestamp":1765030984797,"user_tz":-330,"elapsed":22,"user":{"displayName":"Sam K","userId":"13411932392943204951"}},"outputId":"628a07fd-13f3-4e62-d806-b58e95dc2f61"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded 2 documents\n"]}]},{"cell_type":"markdown","source":["## PyPDFLoader\n","\n","`PyPDFLoader` loads one Document object per PDF page, extracting text and metadata automatically.\n","\n","`PyPDFLoader` uses the pypdf library under the hood to parse PDF files. Each page becomes a separate Document with `page_content` (the text) and `metadata` (including filename and page number). This is useful for RAG applications, document analysis, and knowledge base construction."],"metadata":{"id":"9aqWdKQ5FdK3"}},{"cell_type":"code","source":["!pip install -qU pypdf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Gp89vOiGBvX","executionInfo":{"status":"ok","timestamp":1765031861100,"user_tz":-330,"elapsed":7010,"user":{"displayName":"Sam K","userId":"13411932392943204951"}},"outputId":"00aea051-7fb7-48c2-dedd-272546b566d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/329.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/329.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.5/329.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["from langchain_community.document_loaders import PyPDFLoader\n","\n","# Load a PDF file\n","loader = PyPDFLoader(\"./data/ai_agents_build.pdf\")\n","docs = loader.load()\n","\n","# Each page is a separate Document\n","print(f\"Total pages: {len(docs)}\")\n","print('------')\n","print(f\"First page content: {docs[0].page_content[:200]}\")\n","print('------')\n","print(f\"Metadata: {docs[0].metadata}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VdSdkPVlFvWq","executionInfo":{"status":"ok","timestamp":1765031886216,"user_tz":-330,"elapsed":284,"user":{"displayName":"Sam K","userId":"13411932392943204951"}},"outputId":"a2d14af6-c403-4f4a-8abc-e0402bb3d573"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total pages: 5\n","------\n","First page content: Arti\u0000cial intelligence agents represent a paradigm shift in how we build autonomous\n","systems. Unlike traditional applications that follow pre-de\u0000ned logic paths, AI agents\n","leverage large language model\n","------\n","Metadata: {'producer': 'Skia/PDF m127', 'creator': 'Chromium', 'creationdate': '2025-12-06T13:39:34+00:00', 'moddate': '2025-12-06T13:39:34+00:00', 'source': './data/ai_agents_build.pdf', 'total_pages': 5, 'page': 0, 'page_label': '1'}\n"]}]},{"cell_type":"markdown","source":["**Metadata Handling**\n","\n","The metadata includes `source` (file path) and `page` (0-indexed page number). Use this when embedding and retrieving documents so you can cite the exact source."],"metadata":{"id":"9EdYhj-XG7zA"}},{"cell_type":"code","source":["# Access page information for citations\n","for doc in docs:\n","    source = doc.metadata['source']\n","    page_num = doc.metadata['page']\n","    print(f\"Source: {source}, Page: {page_num + 1}\")  # +1 for human-readable numbering"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KkoiAzxuG2Vy","executionInfo":{"status":"ok","timestamp":1765032083652,"user_tz":-330,"elapsed":20,"user":{"displayName":"Sam K","userId":"13411932392943204951"}},"outputId":"183471c4-3742-4553-bb58-41c750996e91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Source: ./data/ai_agents_build.pdf, Page: 1\n","Source: ./data/ai_agents_build.pdf, Page: 2\n","Source: ./data/ai_agents_build.pdf, Page: 3\n","Source: ./data/ai_agents_build.pdf, Page: 4\n","Source: ./data/ai_agents_build.pdf, Page: 5\n"]}]},{"cell_type":"markdown","source":["**Text Extraction Limitations**\n","\n","PyPDFLoader may struggle with:\n","\n","- Scanned PDFs / images → Use OCR tools like Unstructured, MathPix, or PyMuPDF4LLM instead\n","- Complex layouts (tables, multi-column) → Text ordering may be incorrect\n","- Non-text elements (images, charts) → Extracted as empty strings"],"metadata":{"id":"JQ1ZR5QyHX2c"}},{"cell_type":"code","source":["!pip install -qU pdfminer.six\n","!pip install -qU unstructured"],"metadata":{"id":"Pnw5YvQ9H1qx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# For better PDF handling with complex layouts:\n","\n","from langchain_community.document_loaders import UnstructuredPDFLoader\n","\n","loader = UnstructuredPDFLoader(\"./data/ai_agents_build.pdf\")\n","docs = loader.load()  # Better for tables and structured content\n","\n","print(f\"Total pages: {len(docs)}\")\n","print('------')\n","print(f\"First page content: {docs[0].page_content[:200]}\")\n","print('------')\n","print(f\"Metadata: {docs[0].metadata}\")"],"metadata":{"id":"VetSN9QdHn05"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## CSVLoader\n","\n","`CSVLoader` loads CSV files and converts each row into a `Document` object with the row content and metadata.\n","\n","`CSVLoader` is a simple but effective document loader that treats each row of your CSV as a document.\n","\n","It extracts the data and converts it into LangChain's Document format, which is essential for use with RAG systems, embeddings, and LLMs.\n","\n","**Column Handling**: `CSVLoader` includes all CSV columns in the page_content by default. If your CSV has many columns or sensitive information, you may want to use alternative loaders or preprocess your CSV to include only relevant columns."],"metadata":{"id":"1ObwObm9coG7"}},{"cell_type":"code","source":["from langchain_community.document_loaders import CSVLoader\n","\n","# Initialize the loader with your CSV file\n","loader = CSVLoader(\n","    file_path=\"./data/it_company_salaries.csv\"\n",")\n","\n","# Load all documents at once\n","documents = loader.load()\n","\n","# Each document contains:\n","# - page_content: the row data as a string\n","# - metadata: source information\n","print(documents[0].page_content)\n","print('------')\n","print(documents[0].metadata)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Ghp166XdHSL","executionInfo":{"status":"ok","timestamp":1765037935341,"user_tz":-330,"elapsed":50,"user":{"displayName":"Sam K","userId":"13411932392943204951"}},"outputId":"6c42d86b-22df-43c2-d3f4-f2e985f66537"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Role: QA Engineer\n","Experience_Years: 13\n","Salary_INR_LPA: 23\n","Location: Noida\n","Tech_Stack: Rust, WebAssembly\n","Employment_Type: Full-Time\n","------\n","{'source': './data/it_company_salaries.csv', 'row': 0}\n"]}]},{"cell_type":"markdown","source":["**Lazy Loading for Large Files**\n","\n","For large CSV files, use lazy_load() to process rows incrementally without loading everything into memory:"],"metadata":{"id":"MR-iZcwMeDFC"}},{"cell_type":"code","source":["# Process documents one at a time\n","for document in loader.lazy_load():\n","    print(document.page_content)\n","    # Process individual rows before loading the next"],"metadata":{"id":"Y8ZhxEV6eHMo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## WebBaseLoader\n","\n","`WebBaseLoader` fetches and parses HTML from URLs into LangChain-compatible `Document` objects using `BeautifulSoup`."],"metadata":{"id":"FkHMk0lZfaZr"}},{"cell_type":"code","source":["from langchain_community.document_loaders import WebBaseLoader\n","\n","# Basic usage - load a single URL\n","loader = WebBaseLoader(\"https://www.example.com\")\n","docs = loader.load()\n","\n","print(docs)\n","print('------')\n","\n","# Load multiple URLs\n","urls = [\n","    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n","    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n","    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n","]\n","docs = [WebBaseLoader(url).load() for url in urls]\n","docs_list = [item for sublist in docs for item in sublist]  # Flatten list\n","\n","print(docs_list[0].page_content[:50])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6GqVYzuhfjjg","executionInfo":{"status":"ok","timestamp":1765038794714,"user_tz":-330,"elapsed":769,"user":{"displayName":"Sam K","userId":"13411932392943204951"}},"outputId":"fae41a8a-f771-40dc-be30-9bb7fb07d071"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Document(metadata={'source': 'https://www.example.com', 'title': 'Example Domain', 'language': 'en'}, page_content='Example DomainExample DomainThis domain is for use in documentation examples without needing permission. Avoid use in operations.Learn more\\n')]\n","------\n","\n","\n","\n","\n","\n","\n","LLM Powered Autonomous Agents | Lil'Log\n","\n","\n","\n","\n","\n"]}]},{"cell_type":"markdown","source":["**Customizing HTML Parsing with BeautifulSoup**\n","\n","By default, `WebBaseLoader` extracts ALL visible text. Use `bs_kwargs` to filter specific HTML elements:\n"],"metadata":{"id":"Hi5ygbeHiPXy"}},{"cell_type":"code","source":["!pip install -qU beautifulsoup4"],"metadata":{"id":"W8Qf8aIBiouY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from bs4 import SoupStrainer\n","\n","# Only extract content from specific CSS classes\n","loader = WebBaseLoader(\n","    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n","    bs_kwargs={\n","        \"parse_only\": SoupStrainer(\n","            class_=[\"post-content\", \"post-title\", \"post-header\"]\n","        )\n","    }\n",")\n","docs = loader.load()\n","\n","print(docs[0].page_content[:50])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UA_FvtGjiY9f","executionInfo":{"status":"ok","timestamp":1765039518530,"user_tz":-330,"elapsed":155,"user":{"displayName":"Sam K","userId":"13411932392943204951"}},"outputId":"92257665-2f44-4ea4-91a6-c3caa16eae3f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","      LLM Powered Autonomous Agents\n","    \n","Date: J\n"]}]},{"cell_type":"markdown","source":["**HTTP errors aren't caught**\n","\n","If a URL returns 404, 500, or times out, `WebBaseLoader` will raise an exception. Wrap in try-except for production:"],"metadata":{"id":"kKk-aM2xkxek"}},{"cell_type":"code","source":["from urllib.error import URLError, HTTPError\n","\n","url = \"https://www.example.com\"\n","\n","try:\n","    docs = WebBaseLoader(url).load()\n","except (URLError, HTTPError) as e:\n","    print(f\"Failed to load {url}: {e}\")"],"metadata":{"id":"veR0iZABk2wD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## SQLDatabaseLoader\n","\n"],"metadata":{"id":"7L6I8EyZj11i"}},{"cell_type":"code","source":["from langchain_community.document_loaders import SQLDatabaseLoader\n","from langchain_community.utilities.sql_database import SQLDatabase\n","\n","# Create database connection (supports SQLite, PostgreSQL, MySQL, etc.)\n","db = SQLDatabase.from_uri(\"sqlite:///data/smartphones.db\")\n","print(type(db))\n","print('------')\n","\n","# Get schema information\n","schema = db.get_table_info()\n","print(schema)\n","print('------')\n","\n","\n","# Execute a query\n","loader = SQLDatabaseLoader(\n","    db=db,\n","    query=\"SELECT * FROM brands\"\n",")\n","docs = loader.load()\n","\n","print(docs[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"RVZBub1tj43P","executionInfo":{"status":"ok","timestamp":1765075185676,"user_tz":-330,"elapsed":22,"user":{"displayName":"Sam K","userId":"13411932392943204951"}},"outputId":"59fd7d18-518b-4dca-ed63-7988121f4447"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'langchain_community.utilities.sql_database.SQLDatabase'>\n","------\n","\n","CREATE TABLE brands (\n","\tbrand_id INTEGER, \n","\tbrand_name TEXT\n",")\n","\n","/*\n","3 rows from brands table:\n","brand_id\tbrand_name\n","1\tSamsung\n","2\tApple\n","3\tOnePlus\n","*/\n","\n","\n","CREATE TABLE reviews (\n","\treview_id INTEGER, \n","\tphone_id INTEGER, \n","\trating INTEGER, \n","\tcomment TEXT\n",")\n","\n","/*\n","3 rows from reviews table:\n","review_id\tphone_id\trating\tcomment\n","1\t63\t3\tGreat performance\n","2\t51\t4\tGreat performance\n","3\t66\t4\tVery fast and smooth\n","*/\n","\n","\n","CREATE TABLE smartphones (\n","\tphone_id INTEGER, \n","\tbrand_id INTEGER, \n","\tmodel TEXT, \n","\tprice_inr INTEGER, \n","\tram TEXT, \n","\tstorage TEXT\n",")\n","\n","/*\n","3 rows from smartphones table:\n","phone_id\tbrand_id\tmodel\tprice_inr\tram\tstorage\n","1\t4\tXiaomi Model 49\t61844\t6 GB\t64 GB\n","2\t6\tVivo Model 21\t73804\t4 GB\t64 GB\n","3\t7\tOppo Model 17\t58916\t8 GB\t64 GB\n","*/\n","------\n","page_content='brand_id: 1\n","brand_name: Samsung'\n"]}]},{"cell_type":"code","source":["# Execute a query directly on DB\n","result = db.run(\"SELECT * FROM brands LIMIT 5\")\n","print(result)\n","print(type(result))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eTAlwr16r8Qj","executionInfo":{"status":"ok","timestamp":1765075505007,"user_tz":-330,"elapsed":21,"user":{"displayName":"Sam K","userId":"13411932392943204951"}},"outputId":"edeb24da-0ad2-4d5f-b20e-d10626926c92"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[(1, 'Samsung'), (2, 'Apple'), (3, 'OnePlus'), (4, 'Xiaomi'), (5, 'Realme')]\n","<class 'str'>\n"]}]},{"cell_type":"markdown","source":["**Query Validation Before Execution**\n","\n","\n","Never execute LLM-generated SQL directly. Use the query checker tool:"],"metadata":{"id":"kL_X4N63tNyz"}},{"cell_type":"code","source":["toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n","tools = toolkit.get_tools()\n","\n","# Extract the query checker tool\n","query_checker = next(tool for tool in tools if tool.name == \"sql_db_query_checker\")\n","\n","# Always validate before running\n","user_query = \"SELECT * FROM brandss\"\n","validated = query_checker.invoke({\"query\": user_query})\n","print(validated)  # Review any issues before execution"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xxoP0WuKtSaP","executionInfo":{"status":"ok","timestamp":1765075730091,"user_tz":-330,"elapsed":967,"user":{"displayName":"Sam K","userId":"13411932392943204951"}},"outputId":"e5f0660d-dc5a-44de-c5d1-dba744ef473f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["SELECT * FROM brands;\n"]}]},{"cell_type":"markdown","source":["**Using LLM**"],"metadata":{"id":"XTD9XZg0u2qf"}},{"cell_type":"code","source":["from langchain_community.utilities.sql_database import SQLDatabase\n","from langchain_community.agent_toolkits import SQLDatabaseToolkit, create_sql_agent\n","\n","# Or use the toolkit with an LLM for natural language queries\n","toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n","tools = toolkit.get_tools()\n","\n","# Tools available: sql_db_query, sql_db_schema, sql_db_list_tables, sql_db_query_checker\n","for tool in tools:\n","  print(f\"{tool.name}: {tool.description}\")\n","\n","print('------')\n","\n","# Custom instructions\n","system_prompt = \"\"\"\n","You are a SQL expert assistant. When answering questions:\n","1. Always check available tables first with sql_db_list_tables\n","2. Get the schema with sql_db_schema before writing queries\n","3. Write efficient queries - use LIMIT 10 unless asked for more\n","4. Only use SELECT statements - no INSERT, UPDATE, DELETE\n","5. Double-check queries with sql_db_query_checker before executing\n","6. Explain your findings clearly\n","\n","Be concise and accurate.\n","\"\"\"\n","\n","agent_executor = create_sql_agent(\n","    llm=llm,\n","    toolkit=toolkit,\n","    verbose=True,\n","    agent_type=\"openai-tools\",\n","    system_prompt=system_prompt,  # Pass custom prompt\n","    return_intermediate_steps=True, # Get all tool calls for debugging\n",")\n","\n","# qn = \"What's the schema of the brands table?\"\n","qn = \"Which smartphone has better review?\"\n","\n","result = agent_executor.invoke({\"input\": qn})\n","print(result[\"output\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"iNZAWtb5sW1A","executionInfo":{"status":"ok","timestamp":1765076936429,"user_tz":-330,"elapsed":263712,"user":{"displayName":"Sam K","userId":"13411932392943204951"}},"outputId":"e0ff90c0-324a-44bd-a1e4-cffd1d5e61ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sql_db_query: Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use sql_db_schema to query the correct table fields.\n","sql_db_schema: Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: table1, table2, table3\n","sql_db_list_tables: Input is an empty string, output is a comma-separated list of tables in the database.\n","sql_db_query_checker: Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!\n","------\n","\n","\n","\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m\n","Invoking: `sql_db_list_tables` with `{'tool_input': ''}`\n","\n","\n","\u001b[0m\u001b[38;5;200m\u001b[1;3mbrands, reviews, smartphones\u001b[0m\u001b[32;1m\u001b[1;3m\n","Invoking: `sql_db_schema` with `{'table_names': 'brands, reviews, smartphones'}`\n","\n","\n","\u001b[0m\u001b[33;1m\u001b[1;3m\n","CREATE TABLE brands (\n","\tbrand_id INTEGER, \n","\tbrand_name TEXT\n",")\n","\n","/*\n","3 rows from brands table:\n","brand_id\tbrand_name\n","1\tSamsung\n","2\tApple\n","3\tOnePlus\n","*/\n","\n","\n","CREATE TABLE reviews (\n","\treview_id INTEGER, \n","\tphone_id INTEGER, \n","\trating INTEGER, \n","\tcomment TEXT\n",")\n","\n","/*\n","3 rows from reviews table:\n","review_id\tphone_id\trating\tcomment\n","1\t63\t3\tGreat performance\n","2\t51\t4\tGreat performance\n","3\t66\t4\tVery fast and smooth\n","*/\n","\n","\n","CREATE TABLE smartphones (\n","\tphone_id INTEGER, \n","\tbrand_id INTEGER, \n","\tmodel TEXT, \n","\tprice_inr INTEGER, \n","\tram TEXT, \n","\tstorage TEXT\n",")\n","\n","/*\n","3 rows from smartphones table:\n","phone_id\tbrand_id\tmodel\tprice_inr\tram\tstorage\n","1\t4\tXiaomi Model 49\t61844\t6 GB\t64 GB\n","2\t6\tVivo Model 21\t73804\t4 GB\t64 GB\n","3\t7\tOppo Model 17\t58916\t8 GB\t64 GB\n","*/\u001b[0m\u001b[32;1m\u001b[1;3m\n","Invoking: `sql_db_query_checker` with `{'query': 'SELECT T2.model, T1.rating FROM reviews AS T1 INNER JOIN smartphones AS T2 ON T1.phone_id = T2.phone_id ORDER BY T1.rating DESC LIMIT 10'}`\n","\n","\n","\u001b[0m\u001b[36;1m\u001b[1;3mThe query appears to be well-written and does not contain any of the common mistakes listed. Here is the original query:\n","\n","```sql\n","SELECT T2.model, T1.rating \n","FROM reviews AS T1 \n","INNER JOIN smartphones AS T2 \n","ON T1.phone_id = T2.phone_id \n","ORDER BY T1.rating DESC \n","LIMIT 10\n","```\u001b[0m\u001b[32;1m\u001b[1;3m\n","Invoking: `sql_db_query` with `{'query': 'SELECT T2.model, T1.rating \\nFROM reviews AS T1 \\nINNER JOIN smartphones AS T2 \\nON T1.phone_id = T2.phone_id \\nORDER BY T1.rating DESC \\nLIMIT 10'}`\n","\n","\n","\u001b[0m\u001b[36;1m\u001b[1;3m[('Xiaomi Model 36', 5), ('Vivo Model 40', 5), ('Xiaomi Model 24', 5), ('OnePlus Model 24', 5), ('Google Model 44', 5), ('Realme Model 46', 5), ('Realme Model 29', 5), ('Nothing Model 12', 5), ('Apple Model 45', 5), ('Apple Model 29', 5)]\u001b[0m\u001b[32;1m\u001b[1;3mThe smartphone with the better review is Xiaomi Model 36, which has a rating of 5 out of 5 stars.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","The smartphone with the better review is Xiaomi Model 36, which has a rating of 5 out of 5 stars.\n"]}]},{"cell_type":"markdown","source":["# Section 3 - LangChain Memory"],"metadata":{"id":"34fyz4Vg7buw"}},{"cell_type":"markdown","source":["Adding memory to a RAG system is essential for maintaining conversation context and enabling multi-turn interactions where the model understands previous exchanges.\n","\n","\n","* RunnableWithMessageHistory\n","* create_agent with a checkpointer\n"],"metadata":{"id":"r3pww9uG7u-d"}},{"cell_type":"markdown","source":["### RunnableWithMessageHistory\n","\n","`RunnableWithMessageHistory` is a legacy LangChain pattern (v0.x) for adding message history to runnables."],"metadata":{"id":"miQutZqrZLrR"}},{"cell_type":"code","source":["from langchain.runnables.history import RunnableWithMessageHistory\n","from langchain.schema import HumanMessage, AIMessage\n","from langchain_community.chat_message_histories import ChatMessageHistory\n","\n","# Define a function to get message history by session ID\n","store = {}  # Simple in-memory store\n","\n","def get_session_history(session_id: str):\n","    \"\"\"Retrieve or create chat message history for a session\"\"\"\n","    if session_id not in store:\n","        store[session_id] = ChatMessageHistory()\n","    return store[session_id]\n","\n","# Wrap the chain with message history\n","runnable_with_history = RunnableWithMessageHistory(\n","    llm,\n","    get_session_history,\n","    input_messages_key=\"messages\",\n","    history_messages_key=\"history\"\n",")\n","\n","# Use it in conversation\n","session_id = \"user_123\"\n","\n","# First turn\n","result = runnable_with_history.invoke(\n","    {\"messages\": [HumanMessage(content=\"What is task decomposition?\")]},\n","    config={\"configurable\": {\"session_id\": session_id}}\n",")\n","print(result.content)\n","print('------')\n","\n","# Second turn - history is automatically retrieved\n","result = runnable_with_history.invoke(\n","    {\"messages\": [HumanMessage(content=\"What are extensions of that method?\")]},\n","    config={\"configurable\": {\"session_id\": session_id}}\n",")\n","# The model now has access to the first question in history\n","print(result.content)\n","print('------')\n","\n","history = get_session_history(session_id)\n","history_messages = history.get_messages()\n","print(history_messages)\n"],"metadata":{"id":"bAnvZfarrGRr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Using persistance storage\n","\n","from langchain_community.chat_message_histories import SQLChatMessageHistory\n","\n","def get_session_history(session_id):\n","  return SQLChatMessageHistory(session_id, \"sqlite:///chat_history.db\")"],"metadata":{"id":"GWmtxIMZeEI8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Modern Approach (LangChain v1+)\n","\n","Use `create_agent` with a checkpointer instead. This is much simpler and handles message history automatically:"],"metadata":{"id":"_Q_1ojishepr"}},{"cell_type":"code","source":["from langchain.agents import create_agent\n","from langchain.tools import tool\n","from langgraph.checkpoint.memory import InMemorySaver\n","\n","# Define your RAG retrieval tool\n","@tool\n","def retrieve_context(query: str) -> str:\n","  \"\"\"Retrieve relevant documents from vector store\"\"\"\n","  # Your RAG logic here\n","  return f\"Retrieved documents for: {query}\"\n","\n","# Create agent with memory\n","checkpointer = InMemorySaver()  # Or PostgresSaver for production\n","\n","# Use database-backed storage\n","# checkpointer = PostgresSaver.from_conn_string(\n","#     \"postgresql://user:password@localhost/langchain_db\"\n","# )\n","\n","agent = create_agent(\n","  model=llm,\n","  tools=[retrieve_context],\n","  checkpointer=checkpointer,  # This enables message history!\n",")\n","\n","config = {\"configurable\": {\"thread_id\": \"user_123\"}}\n","\n","# First turn\n","response1 = agent.invoke(\n","  {\"messages\": [{\"role\": \"user\", \"content\": \"What is task decomposition? Answer me in single sentence\"}]},\n","  {\"configurable\": {\"thread_id\": \"user_123\"}}  # Thread ID = session ID\n",")\n","print(response1[\"messages\"][-1].content)\n","print('------')\n","\n","# Second turn - message history is automatically included\n","response2 = agent.invoke(\n","    {\"messages\": [{\"role\": \"user\", \"content\": \"What are extensions of that?\"}]},\n","    config=config  # Same thread = same history\n",")\n","# The agent remembers the first question\n","print(response2[\"messages\"][-1].content)\n","print('------')\n","\n","# View full conversation history\n","print(\"Full conversation:\")\n","for msg in response2[\"messages\"]:\n","  print(f\"> {msg.type}: {msg.content}\")\n","\n","print('------')\n","\n","# Get current state (latest messages)\n","current_state = agent.get_state(config)\n","print(\"Current messages:\")\n","for msg in current_state.values[\"messages\"]:\n","  print(f\"> {msg.type}: {msg.content}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ruWq4sufhmEP","executionInfo":{"status":"ok","timestamp":1765123855636,"user_tz":-330,"elapsed":12353,"user":{"displayName":"Sam K","userId":"13411932392943204951"}},"outputId":"ac320b09-6261-41dd-cd9d-3f7161750e9f"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Task decomposition is a problem-solving strategy that involves breaking down complex tasks or problems into smaller, more manageable subtasks or components to facilitate understanding, planning, and execution.\n","------\n","Some extensions of task decomposition include:\n","\n","1. Hierarchical Task Decomposition: Breaking down tasks into a hierarchical structure of subtasks, with higher-level tasks decomposed into lower-level ones.\n","2. Functional Decomposition: Breaking down tasks into smaller functions or activities that need to be performed to achieve the overall goal.\n","3. Recursive Decomposition: Breaking down tasks into smaller subtasks, and then further decomposing those subtasks into even smaller ones, until the task is fully understood and manageable.\n","\n","These extensions can help to further simplify complex tasks and make them more manageable.\n","------\n","Full conversation:\n","> human: What is task decomposition? Answer me in single sentence\n","> ai: Task decomposition is a problem-solving strategy that involves breaking down complex tasks or problems into smaller, more manageable subtasks or components to facilitate understanding, planning, and execution.\n","> human: What are extensions of that?\n","> ai: Some extensions of task decomposition include:\n","\n","1. Hierarchical Task Decomposition: Breaking down tasks into a hierarchical structure of subtasks, with higher-level tasks decomposed into lower-level ones.\n","2. Functional Decomposition: Breaking down tasks into smaller functions or activities that need to be performed to achieve the overall goal.\n","3. Recursive Decomposition: Breaking down tasks into smaller subtasks, and then further decomposing those subtasks into even smaller ones, until the task is fully understood and manageable.\n","\n","These extensions can help to further simplify complex tasks and make them more manageable.\n","------\n","Current messages:\n","> human: What is task decomposition? Answer me in single sentence\n","> ai: Task decomposition is a problem-solving strategy that involves breaking down complex tasks or problems into smaller, more manageable subtasks or components to facilitate understanding, planning, and execution.\n","> human: What are extensions of that?\n","> ai: Some extensions of task decomposition include:\n","\n","1. Hierarchical Task Decomposition: Breaking down tasks into a hierarchical structure of subtasks, with higher-level tasks decomposed into lower-level ones.\n","2. Functional Decomposition: Breaking down tasks into smaller functions or activities that need to be performed to achieve the overall goal.\n","3. Recursive Decomposition: Breaking down tasks into smaller subtasks, and then further decomposing those subtasks into even smaller ones, until the task is fully understood and manageable.\n","\n","These extensions can help to further simplify complex tasks and make them more manageable.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"lhucYGvvil4Q"},"execution_count":null,"outputs":[]}]}